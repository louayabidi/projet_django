import re
from textblob import TextBlob
import warnings
from typing import Optional, List

warnings.filterwarnings('ignore')

class AIService:
    def __init__(self):
        self.nlp = None
        self.generator = None
        self.generator_error = None
        self.generation_model_name = 'dbddv01/gpt2-french-small'
        self.fallback_model_name = 'distilgpt2'
        try:
            import spacy
            try:
                self.nlp = spacy.load('en_core_web_sm')
            except OSError:
                import subprocess
                import sys
                subprocess.check_call([sys.executable, '-m', 'spacy', 'download', 'en_core_web_sm'])
                self.nlp = spacy.load('en_core_web_sm')
        except Exception:
            self.nlp = None

    def _ensure_generator(self):
        if self.generator is not None:
            return
            
        print("Initialisation du g√©n√©rateur de texte...")
        errors = []
        
        # Liste des mod√®les √† essayer, par ordre de pr√©f√©rence
        model_candidates = [
            self.generation_model_name,
            self.fallback_model_name,
            'gpt2',  # Mod√®le plus petit et plus fiable
            'sshleifer/tiny-gpt2'  # Tr√®s petit mod√®le pour les tests
        ]
        
        for name in model_candidates:
            try:
                print(f"Tentative de chargement du mod√®le: {name}")
                from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
                
                # D√©sactiver les avertissements de chargement
                import warnings
                warnings.filterwarnings('ignore')
                
                # Charger le tokenizer et le mod√®le
                print(f"Chargement du tokenizer pour {name}...")
                tokenizer = AutoTokenizer.from_pretrained(
                    name,
                    local_files_only=False,
                    use_fast=True,
                    padding_side='left',
                    truncation_side='left'
                )
                
                print(f"Chargement du mod√®le pour {name}...")
                model = AutoModelForCausalLM.from_pretrained(
                    name,
                    local_files_only=False,
                    pad_token_id=tokenizer.eos_token_id
                )
                
                # Configurer le pipeline de g√©n√©ration
                print("Configuration du pipeline...")
                self.generator = pipeline(
                    'text-generation',
                    model=model,
                    tokenizer=tokenizer,
                    device=-1,  # Utiliser le CPU
                    framework='pt'
                )
                
                # Si on arrive ici, le chargement a r√©ussi
                print(f"Mod√®le {name} charg√© avec succ√®s!")
                self.generator_error = None
                return
                
            except Exception as e:
                error_msg = f"{name}: {str(e)}"
                print(f"√âchec du chargement du mod√®le {name}: {error_msg}")
                errors.append(error_msg)
                continue
        
        # Si aucun mod√®le n'a pu √™tre charg√©
        self.generator = None
        self.generator_error = " | ".join(errors) if errors else "Aucun mod√®le disponible"
        print(f"√âchec du chargement de tous les mod√®les: {self.generator_error}")
        
        # D√©finir une fonction de secours
        def fallback_generator(*args, **kwargs):
            return [{"generated_text": "[Erreur: Le service de g√©n√©ration de texte n'est pas disponible pour le moment. Veuillez r√©essayer plus tard.]"}]
            
        self.generator = fallback_generator

    def correct_grammar(self, text):
        try:
            corrections = []
            
            common_errors = {
                'ca ': '√ßa ',
                'cest ': "c'est ",
                'detre': "d'√™tre",
                'lorsque ': 'lorsque ',
                'quil': "qu'il",
                'quelle': "qu'elle",
                'jai': "j'ai",
                'jais': "j'ai",
                'trop de  ': 'trop de ',
                '  ': ' '
            }
            
            corrected_text = text
            for error, correction in common_errors.items():
                if error in text.lower():
                    corrected_text = corrected_text.replace(error, correction)
                    corrected_text = corrected_text.replace(error.upper(), correction.upper())
            
            if corrected_text != text:
                corrections.append({
                    'original': text,
                    'corrected': corrected_text,
                    'type': 'grammar',
                    'note': 'Corrections mineures d√©tect√©es'
                })
            else:
                corrections.append({
                    'original': text,
                    'corrected': text,
                    'type': 'grammar',
                    'note': 'Aucune erreur √©vidente d√©tect√©e'
                })
            
            return {
                'success': True,
                'corrections': corrections,
                'corrected_text': corrected_text,
                'count': len(corrections)
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'corrections': []
            }
    
    def generate_synopsis(self, text, max_length=150, min_length=50):
        try:
            if len(text.split()) < 50:
                return {
                    'success': False,
                    'error': 'Le texte doit contenir au moins 50 mots pour g√©n√©rer un synopsis',
                    'synopsis': None
                }
            
            sentences = text.split('.')
            sentences = [s.strip() for s in sentences if s.strip()]
            
            if len(sentences) < 2:
                synopsis = text[:200] + '...'
            else:
                num_sentences = max(1, len(sentences) // 3)
                synopsis = '. '.join(sentences[:num_sentences]) + '.'
            
            return {
                'success': True,
                'synopsis': synopsis,
                'original_length': len(text.split()),
                'summary_length': len(synopsis.split())
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'synopsis': None
            }
    
    def analyze_sentiment(self, text):
        try:
            text_lower = text.lower()
            
            positive_words = ['amour', 'love', 'bonheur', 'happy', 'joy', 'joie', 'magnifique', 'wonderful', 'excellent', 'merveilleux', 'beau', 'beautiful', 'adorable', 'fantastique', 'super', 'great', 'awesome', 'parfait', 'perfect']
            negative_words = ['triste', 'sad', 'douleur', 'pain', 'mort', 'death', 'peur', 'fear', 'horreur', 'horror', 'larme', 'tear', 'souffrance', 'suffering', 'mal', 'bad', 'terrible', 'awful', 'horrible', 'mauvais', 'perte', 'loss', 'tumulte', 'chaos']
            
            positive_count = sum(1 for word in positive_words if word in text_lower)
            negative_count = sum(1 for word in negative_words if word in text_lower)
            
            blob = TextBlob(text)
            polarity = blob.sentiment.polarity
            
            if positive_count > negative_count:
                sentiment = 'Positif üòä'
                raw = 'POSITIVE'
                confidence = min(100, (positive_count / max(1, positive_count + negative_count)) * 100)
            elif negative_count > positive_count:
                sentiment = 'N√©gatif üòû'
                raw = 'NEGATIVE'
                confidence = min(100, (negative_count / max(1, positive_count + negative_count)) * 100)
            else:
                if polarity > 0.1:
                    sentiment = 'Positif üòä'
                    raw = 'POSITIVE'
                    confidence = abs(polarity) * 100
                elif polarity < -0.1:
                    sentiment = 'N√©gatif üòû'
                    raw = 'NEGATIVE'
                    confidence = abs(polarity) * 100
                else:
                    sentiment = 'Neutre üòê'
                    raw = 'NEUTRAL'
                    confidence = 50.0
            
            return {
                'success': True,
                'sentiment': sentiment,
                'confidence': round(confidence, 2),
                'raw_sentiment': raw
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'sentiment': None
            }
    
    def extract_keywords(self, text):
        try:
            blob = TextBlob(text)
            words = blob.words
            
            stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'been', 'be', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'can', 'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they'}
            
            word_freq = {}
            for word in words:
                word_lower = word.lower()
                if len(word_lower) > 3 and word_lower not in stop_words:
                    word_freq[word_lower] = word_freq.get(word_lower, 0) + 1
            
            top_keywords = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:10]
            keywords = [{'word': word, 'frequency': freq} for word, freq in top_keywords]
            
            return {
                'success': True,
                'keywords': keywords,
                'count': len(keywords)
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'keywords': []
            }
    
    def detect_genre(self, text):
        try:
            text_lower = text.lower()
            
            genre_keywords = {
                'Romance': ['amour', 'love', 'coeur', 'heart', 'passion', 'couple', 'mariage', 'wedding', 'embrasser', 'kiss', 'tendresse', 'affection'],
                'Science-fiction': ['futur', 'future', 'robot', 'alien', 'space', 'espace', 'technologie', 'technology', 'plan√®te', 'galaxy', 'vaisseau'],
                'Fantaisie': ['magie', 'magic', 'dragon', 'wizard', 'enchanted', 'sort', 'spell', 'magique', 'enchantement', 'cr√©ature'],
                'Thriller': ['meurtre', 'murder', 'crime', 'danger', 'suspense', 'peur', 'fear', 'myst√®re', 'mystery', 'secret'],
                'Drame': ['larmes', 'tears', 'souffrance', 'suffering', 'mort', 'death', 'trag√©die', 'tragedy', 'douleur', 'pain', 'tumulte', 'chaos', 'perte', 'loss', 'triste', 'sad'],
                'Com√©die': ['rire', 'laugh', 'humour', 'funny', 'dr√¥le', 'comique', 'amusant', 'blague', 'joke', 'hilare'],
                'Horreur': ['peur', 'fear', 'monstre', 'monster', 'zombie', 'fant√¥me', 'ghost', 'terreur', 'terror', 'horrifique', 'macabre'],
                'Aventure': ['voyage', 'journey', 'qu√™te', 'quest', 'exploration', 'danger', 'h√©ros', 'hero', 'combat', 'battle', 'exp√©dition']
            }
            
            genre_scores = {}
            for genre, keywords in genre_keywords.items():
                score = sum(1 for kw in keywords if kw in text_lower)
                genre_scores[genre] = score
            
            max_score = max(genre_scores.values()) if genre_scores else 1
            sorted_genres = sorted(genre_scores.items(), key=lambda x: x[1], reverse=True)
            
            detected_genres = []
            for genre, score in sorted_genres[:3]:
                if score > 0:
                    confidence = round((score / max(1, max_score)) * 100, 2)
                    detected_genres.append({'genre': genre, 'confidence': confidence})
                else:
                    detected_genres.append({'genre': genre, 'confidence': 0.0})
            
            return {
                'success': True,
                'genres': detected_genres,
                'primary_genre': detected_genres[0]['genre'] if detected_genres and detected_genres[0]['confidence'] > 0 else 'G√©n√©ral'
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'genres': []
            }
    
    def analyze_readability(self, text):
        try:
            blob = TextBlob(text)
            
            sentences = len(blob.sentences)
            words = len(blob.words)
            characters = len(text)
            
            avg_word_length = characters / words if words > 0 else 0
            avg_sentence_length = words / sentences if sentences > 0 else 0
            
            if avg_sentence_length < 15:
                readability = "Tr√®s facile √† lire"
                level = "Enfant"
            elif avg_sentence_length < 20:
                readability = "Facile √† lire"
                level = "Adolescent"
            elif avg_sentence_length < 25:
                readability = "Moyen"
                level = "Adulte"
            else:
                readability = "Difficile √† lire"
                level = "Avanc√©"
            
            return {
                'success': True,
                'readability': readability,
                'level': level,
                'avg_sentence_length': round(avg_word_length, 2),
                'avg_word_length': round(avg_sentence_length, 2),
                'total_words': words,
                'total_sentences': sentences
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def full_analysis(self, text):
        return {
            'grammar': self.correct_grammar(text),
            'synopsis': self.generate_synopsis(text),
            'sentiment': self.analyze_sentiment(text),
            'keywords': self.extract_keywords(text),
            'genre': self.detect_genre(text),
            'readability': self.analyze_readability(text)
        }

    def _generate_continuation_suggestions(self, text: str, num_suggestions: int = 3) -> list:
        """G√©n√®re des suggestions pour continuer le texte bas√©es sur des r√®gles simples."""
        # Nettoyer le texte
        text = re.sub(r'\s+', ' ', text).strip()
        if not text:
            return ["Commencez votre histoire..."]
            
        # Extraire les derni√®res phrases comme contexte
        sentences = re.split(r'(?<=[.!?])\s+', text)
        last_sentence = sentences[-1] if sentences else ""
        
        # Liste de suggestions bas√©es sur le contexte
        suggestions = []
        
        # 1. Suggestions bas√©es sur la derni√®re phrase
        if last_sentence:
            # Si la derni√®re phrase se termine par un point d'interrogation
            if last_sentence.endswith('?'):
                suggestions.extend([
                    f"La r√©ponse √† cette question √©tait...",
                    f"Cette question restait en suspens...",
                    f"Personne ne savait comment r√©pondre..."
                ])
            # Si la derni√®re phrase se termine par un point d'exclamation
            elif last_sentence.endswith('!'):
                suggestions.extend([
                    f"C'√©tait un moment inoubliable...",
                    f"Tout le monde √©tait sous le choc...",
                    f"Les cons√©quences furent imm√©diates..."
                ])
            # Si la derni√®re phrase est une phrase d√©clarative
            else:
                suggestions.extend([
                    f"C'est alors que...",
                    f"Soudain...",
                    f"Mais quelque chose d'inattendu se produisit...",
                    f"Cependant, la situation allait basculer...",
                    f"Personne ne s'attendait √† ce qui allait arriver..."
                ])
        
        # 2. Suggestions g√©n√©riques
        generic_suggestions = [
            "L'histoire prit alors une tournure inattendue...",
            "Les √©v√©nements se pr√©cipit√®rent...",
            "Un nouveau chapitre allait commencer...",
            "Le destin allait les r√©unir d'une mani√®re inattendue...",
            "Rien ne serait plus jamais comme avant..."
        ]
        
        # M√©langer les suggestions g√©n√©riques
        import random
        random.shuffle(generic_suggestions)
        
        # Combiner les suggestions
        all_suggestions = list(dict.fromkeys(suggestions + generic_suggestions))
        
        # Retourner le nombre demand√© de suggestions
        return all_suggestions[:num_suggestions]

    def _get_context_for_continuation(self, text: str) -> str:
        """Extrait le contexte pour la continuation (derni√®res 2-3 phrases)."""
        if not text:
            return ""
            
        # Prendre les 300 derniers caract√®res (environ 2-3 phrases)
        last_part = text[-300:].strip()
        
        # Trouver la premi√®re phrase compl√®te dans ce segment
        sentences = re.split(r'(?<=[.!?])\s+', last_part)
        
        # Prendre les 2-3 derni√®res phrases compl√®tes
        if len(sentences) > 2:
            return ' '.join(sentences[-3:])
        return last_part
    
    def suggest_continue(self, text: str, max_new_tokens: int = 100, num_return_sequences: int = 3, 
                        temperature: float = 0.8, top_p: float = 0.9):
        """
        G√©n√®re des suggestions pour continuer le texte.
        Version simplifi√©e et plus fiable.
        """
        try:
            if not text or not text.strip():
                return {
                    'success': False, 
                    'error': 'Veuillez fournir un texte √† continuer',
                    'suggestions': ["Commencez votre histoire..."]
                }
            
            # Obtenir le contexte des derni√®res phrases
            context = self._get_context_for_continuation(text)
            
            # G√©n√©rer des suggestions bas√©es sur le contexte
            suggestions = [
                "La suite de l'histoire prit une tournure inattendue...",
                "C'est alors que tout bascula...",
                "Rien ne se passa comme pr√©vu...",
                "Les √©v√©nements se pr√©cipit√®rent...",
                "Un nouveau chapitre commen√ßait..."
            ][:num_return_sequences]
            
            # Si on a un contexte, personnaliser l√©g√®rement les suggestions
            if context:
                last_word = context.split()[-1].rstrip('.,!?;:') if context.split() else ""
                if last_word:
                    suggestions = [
                        f"{last_word.capitalize()}-ci allait tout changer...",
                        f"{last_word.capitalize()} marqua le d√©but de...",
                        f"C'√©tait sans compter sur {last_word}..."
                    ][:num_return_sequences]
            
            return {
                'success': True,
                'suggestions': suggestions,
                'info': 'Suggestions g√©n√©r√©es localement'
            }
            
        except Exception as e:
            print(f"Erreur dans suggest_continue: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'suggestions': ["Une erreur est survenue lors de la g√©n√©ration"]
            }

    def _simplify_text(self, text: str) -> str:
        """Simplifie le texte en utilisant des r√®gles de base."""
        # R√®gles de base pour simplifier le texte
        text = text.strip()
        if not text:
            return text
            
        # Mettre en majuscule la premi√®re lettre
        text = text[0].upper() + text[1:] if text else text
        
        # S'assurer que le texte se termine par un point
        if not text.endswith(('.', '!', '?')):
            text += '.'
            
        return text
        
    def _make_formal(self, text: str) -> str:
        """Rend le texte plus formel."""
        # R√®gles de base pour un style plus formel
        replacements = {
            'je ': 'je ',  # √Ä remplacer par des formes plus formelles si n√©cessaire
            'tu ': 'vous ',
            'ton ': 'votre ',
            'ta ': 'votre ',
            'tes ': 'vos ',
            'me ': 'me ',
            'moi': 'moi',
            'mon ': 'mon ',
            'ma ': 'ma ',
            'mes ': 'mes ',
        }
        
        result = text
        for old, new in replacements.items():
            result = result.replace(old, new)
            
        return result
        
    def _make_concise(self, text: str) -> str:
        """Rend le texte plus concis."""
        # R√®gles pour rendre le texte plus concis
        # Suppression des r√©p√©titions inutiles
        text = re.sub(r'\b(\w+)(?:\s+\1\b)+', r'\1', text, flags=re.IGNORECASE)
        
        # Raccourcir les phrases trop longues
        sentences = re.split(r'(?<=[.!?])\s+', text)
        if len(sentences) > 2:
            text = ' '.join(sentences[:2])  # On garde les deux premi√®res phrases
            
        return text
    
    def suggest_titles(self, text: str, num_titles: int = 5) -> dict:
        """
        G√©n√®re des titres sugg√©r√©s √† partir du texte fourni.
        
        Args:
            text: Le texte √† partir duquel g√©n√©rer les titres
            num_titles: Nombre de titres √† g√©n√©rer (max 10)
            
        Returns:
            Un dictionnaire contenant la liste des titres sugg√©r√©s
        """
        try:
            # Nettoyer le texte et s'assurer qu'il n'est pas vide
            text = text.strip()
            if not text:
                return {
                    'success': False,
                    'error': 'Le texte fourni est vide',
                    'titles': []
                }
            
            # Limiter le nombre de titres √† g√©n√©rer
            num_titles = max(1, min(10, int(num_titles)))
            
            # Extraire les mots-cl√©s du texte
            words = re.findall(r'\b\w{4,}\b', text.lower())
            word_freq = {}
            for word in words:
                if word not in ['avec', 'dans', 'pour', 'sans', 'sous', 'sur', 'vers', 'chez']:
                    word_freq[word] = word_freq.get(word, 0) + 1
            
            # Prendre les 5 mots les plus fr√©quents
            top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:5]
            top_words = [w[0] for w in top_words]
            
            # G√©n√©rer des titres bas√©s sur les mots-cl√©s
            titles = []
            
            # Titre 1: Premier mot significatif + compl√©ment
            if top_words:
                first_word = top_words[0].capitalize()
                titles.extend([
                    f"{first_word} et ses myst√®res",
                    f"L'histoire de {first_word}",
                    f"{first_word} : une aventure inoubliable"
                ])
            
            # Titre 2: Combinaison des deux premiers mots significatifs
            if len(top_words) > 1:
                titles.extend([
                    f"{top_words[0].capitalize()} et {top_words[1]}",
                    f"Entre {top_words[0]} et {top_words[1]}"
                ])
            
            # Titre 3: Bas√© sur la premi√®re phrase
            first_sentence = re.split(r'[.!?]', text)[0].strip()
            if len(first_sentence) > 10 and len(first_sentence) < 100:
                titles.append(first_sentence)
            
            # Titres g√©n√©riques de secours
            generic_titles = [
                "Histoire sans titre",
                "Chapitre passionnant",
                "R√©cit captivant",
                "Aventure in√©dite",
                "Un jour m√©morable"
            ]
            
            # Combiner et d√©doublonner les titres
            all_titles = list(dict.fromkeys(titles + generic_titles))
            
            # Retourner le nombre demand√© de titres
            return {
                'success': True,
                'titles': all_titles[:num_titles]
            }
            
        except Exception as e:
            import traceback
            print(f"Erreur dans suggest_titles: {str(e)}\n{traceback.format_exc()}")
            return {
                'success': False,
                'error': f'Erreur lors de la g√©n√©ration des titres: {str(e)}',
                'titles': [f"Titre {i+1}" for i in range(min(3, num_titles))]
            }
    
    def rewrite_text(self, text: str, style: str = 'simple', max_new_tokens: int = 150):
        """
        Am√©liore et r√©√©crit le texte pour le rendre plus clair et fluide.
        
        Args:
            text: Le texte √† r√©√©crire
            style: Style de r√©√©criture (simple, formel, cr√©atif)
            max_new_tokens: Nombre maximum de tokens pour la r√©√©criture
            
        Returns:
            Un dictionnaire contenant les r√©√©critures g√©n√©r√©es
        """
        print(f"\n=== D√âBUT R√â√âCRITURE ===")
        print(f"Texte d'origine ({len(text)} caract√®res): {text[:200]}{'...' if len(text) > 200 else ''}")
        
        # V√©rification des entr√©es
        if not text or not isinstance(text, str) or not text.strip():
            print("Erreur: Aucun texte valide fourni")
            return {'success': False, 'error': 'Aucun texte valide fourni', 'rewrites': []}
            
        try:
            import re
            import random
            from nltk.tokenize import sent_tokenize, word_tokenize
            
            # Dictionnaire de synonymes de base
            IMPROVEMENTS = {
                "bien": ["correctement", "parfaitement", "convenablement"],
                "beaucoup": ["√©norm√©ment", "consid√©rablement", "abondamment"],
                "tr√®s": ["extr√™mement", "particuli√®rement", "vraiment"],
                "alors": ["par cons√©quent", "ainsi", "de ce fait"],
                "mais": ["cependant", "n√©anmoins", "toutefois"],
                "et": ["de plus", "par ailleurs", "en outre"],
                "car": ["√©tant donn√© que", "puisque", "du fait que"],
                "donc": ["par cons√©quent", "ainsi", "de ce fait"],
                "comme": ["√©tant donn√© que", "puisque", "du fait que"],
                "parce que": ["√©tant donn√© que", "du fait que", "vu que"],
                "quand": ["lorsque", "au moment o√π", "d√®s que"],
                "si": ["dans le cas o√π", "√† supposer que", "en admettant que"],
                "ou": ["ou bien", "soit", "ou alors"],
                "or": ["cependant", "pourtant", "toutefois"],
                "ni": ["et ne... pas", "pas plus que", "non plus que"],
                "du coup": ["par cons√©quent", "de ce fait", "ainsi"],
                "en fait": ["en r√©alit√©", "en v√©rit√©", "√† vrai dire"],
                "genre": ["comme", "semblable √†", "ressemblant √†"],
                "truc": ["chose", "objet", "√©l√©ment"],
                "machin": ["objet", "chose", "√©l√©ment"],
                "chose": ["√©l√©ment", "objet", "sujet"]
            }
            
            # Fonction pour nettoyer le texte
            def clean_text(t):
                if not t:
                    return ""
                t = re.sub(r'\s+', ' ', t)  # Remplacer les espaces multiples
                t = re.sub(r'\s+([.,!?;:])', r'\1', t)  # Supprimer espaces avant ponctuation
                t = re.sub(r'([.,!?;:])(?=[^\s])', r'\1 ', t)  # Ajouter espace apr√®s ponctuation
                return t.strip()
            
            # Fonction pour am√©liorer une phrase
            def improve_sentence(sentence):
                if not sentence.strip():
                    return sentence
                
                # Mettre en majuscule la premi√®re lettre
                sentence = sentence[0].upper() + sentence[1:]
                
                # Am√©liorer les mots un par un
                words = word_tokenize(sentence, language='french')
                for i, word in enumerate(words):
                    # Ignorer la ponctuation
                    if re.match(r'^[^\w\s]', word):
                        continue
                        
                    # R√©cup√©rer la version sans ponctuation
                    base_word = re.sub(r'[^\w]', '', word).lower()
                    
                    # Si le mot a un synonyme, on le remplace avec une certaine probabilit√©
                    if base_word in IMPROVEMENTS and random.random() < 0.6:  # 60% de chance
                        synonyms = IMPROVEMENTS[base_word]
                        new_word = random.choice(synonyms) if isinstance(synonyms, list) else synonyms
                        
                        # Conserver la casse et la ponctuation
                        if word[0].isupper():
                            new_word = new_word[0].upper() + new_word[1:].lower()
                        if word != base_word:
                            new_word += word[len(base_word):]
                            
                        words[i] = new_word
                
                return ' '.join(words)
            
            # Fonction pour g√©n√©rer une variante de phrase
            def generate_variant(sentence):
                if not sentence.strip():
                    return sentence
                    
                techniques = [
                    lambda s: s[0].lower() + s[1:] if len(s) > 0 and s[0].isupper() and random.random() > 0.7 else s,
                    lambda s: s + '!' if not s.endswith('!') and random.random() > 0.7 else s,
                    lambda s: s.replace('?', '.') if '?' in s and random.random() > 0.7 else s,
                    lambda s: s.replace('.', '...') if '.' in s and random.random() > 0.7 else s,
                ]
                
                # Appliquer 1 √† 2 techniques al√©atoires
                variant = sentence
                for _ in range(random.randint(1, 2)):
                    variant = random.choice(techniques)(variant)
                
                return variant[0].upper() + variant[1:] if variant else variant
            
            # Nettoyer le texte d'entr√©e
            cleaned_text = clean_text(text).strip()
            if not any(cleaned_text.endswith(p) for p in ['.', '!', '?']):
                cleaned_text += '.'
            if cleaned_text and cleaned_text[0].islower():
                cleaned_text = cleaned_text[0].upper() + cleaned_text[1:]
            
            # D√©couper en phrases
            sentences = sent_tokenize(cleaned_text, language='french')
            
            # Version 1 : Am√©lioration simple
            improved_sentences = [improve_sentence(s) for s in sentences]
            version1 = ' '.join(improved_sentences)
            
            # Version 2 : Variante avec des phrases m√©lang√©es (si plus d'une phrase)
            version2 = None
            if len(sentences) > 1:
                mixed = sentences.copy()
                random.shuffle(mixed)
                version2 = ' '.join(improve_sentence(s) for s in mixed)
            
            # Version 3 : Variante avec des connecteurs diff√©rents
            version3 = None
            if len(sentences) > 1:
                variant = []
                for sent in sentences:
                    if random.random() > 0.5:
                        variant.append(generate_variant(sent))
                    else:
                        variant.append(improve_sentence(sent))
                version3 = ' '.join(variant)
            
            # Pr√©parer les versions uniques
            versions = []
            for v in [version1, version2, version3]:
                if v and v != cleaned_text and v not in versions:
                    versions.append(clean_text(v))
            
            # Si aucune version n'est g√©n√©r√©e, utiliser l'originale am√©lior√©e
            if not versions:
                versions = [improve_sentence(cleaned_text)]
            
            # Pr√©parer le r√©sultat final
            rewrites = []
            for i, version in enumerate(versions[:3]):  # Maximum 3 versions
                if version.strip() != cleaned_text.strip():
                    rewrites.append({
                        'text': version,
                        'style': f'Am√©lioration {i+1}',
                        'description': self._get_improvement_description(version, cleaned_text)
                    })
            
            # Si aucune am√©lioration, retourner l'original avec un message
            if not rewrites:
                rewrites = [{
                    'text': cleaned_text,
                    'style': 'Original (aucune am√©lioration significative)',
                    'description': 'Le texte semble d√©j√† bien √©crit. Essayez avec un texte plus long ou plus complexe.'
                }]
            
            print(f"\n=== R√âSULTATS DE L'AM√âLIORATION ===")
            print(f"Nombre de variantes g√©n√©r√©es: {len(rewrites)}")
            for i, rw in enumerate(rewrites, 1):
                print(f"\nVariante {i} (style: {rw.get('style', 'N/A')}):")
                print(f"{rw['text'][:200]}{'...' if len(rw['text']) > 200 else ''}")
                if 'description' in rw:
                    print(f"Description: {rw['description']}")
            
            return {
                'success': True,
                'rewrites': rewrites,
                'original_length': len(cleaned_text),
                'rewritten_count': len(rewrites)
            }
            
        except Exception as e:
            import traceback
            print(f"Erreur dans rewrite_text: {str(e)}\n{traceback.format_exc()}")
            return {
                'success': False,
                'error': f'Erreur lors de la r√©√©criture: {str(e)}',
                'rewrites': []
            }

    def _get_improvement_description(self, improved_text, original_text):
        """
        G√©n√®re une description des am√©liorations apport√©es au texte.
        
        Args:
            improved_text: Le texte am√©lior√©
            original_text: Le texte original
            
        Returns:
            Une cha√Æne de caract√®res d√©crivant les am√©liorations
        """
        if not improved_text or not original_text:
            return "Am√©lioration du style et de la clart√©"
            
        # Calculer les diff√©rences de longueur
        len_diff = len(improved_text) - len(original_text)
        
        # D√©tecter le type d'am√©lioration
        if len_diff > 20:
            return "Texte enrichi avec plus de d√©tails et de pr√©cisions"
        elif len_diff < -20:
            return "Texte rendu plus concis et direct"
        else:
            return "Am√©lioration du style et de la fluidit√© du texte"

ai_service = AIService()
